{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import sasoptpy as so\n",
    "import os\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import HTML\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixture Generating Funtions\n",
    "Generate ticker for visualization and optimization, based on the live fixture info from the Premier League API and any custom fixture timings and probabilities set by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate matchday ticker dataframe, team_fixtures\n",
    "def generate_ticker(gw_range=None, exclude_teams=None, custom_fixtures=None, extra_fixtures=None, generate_all_dataframes=False):\n",
    "\n",
    "    # Infer fixture difficulties\n",
    "    team_priors = pd.read_csv(f'../data/team_priors.csv')\n",
    "    team_priors['h_off'] = round(team_priors['bl_g_for'] * team_priors['home_adv_g'],2)\n",
    "    team_priors['h_def'] = round(team_priors['bl_g_against'] / team_priors['home_adv_g'],2)\n",
    "    team_priors['h_gd'] = team_priors['h_off'] - team_priors['h_def']\n",
    "    team_priors['a_off'] = round(team_priors['bl_g_for'] / team_priors['home_adv_g'],2)\n",
    "    team_priors['a_def'] = round(team_priors['bl_g_against'] * team_priors['home_adv_g'],2)\n",
    "    team_priors['a_gd'] = team_priors['a_off'] - team_priors['a_def']\n",
    "\n",
    "    # Get fixtures and team data from pl api\n",
    "    r = requests.get('https://fantasy.premierleague.com/api/bootstrap-static/')\n",
    "    fpl_data = r.json()\n",
    "    team_data = pd.DataFrame(fpl_data['teams'])\n",
    "    team_data = team_data[['id', 'short_name']].rename(columns={\"id\": \"team_id\"})\n",
    "    team_data = team_data.replace('NFO', 'FOR')\n",
    "    r = requests.get('https://fantasy.premierleague.com/api/fixtures/')\n",
    "    fixtures_data = r.json()\n",
    "    fixtures_data = pd.DataFrame(fixtures_data)\n",
    "    fixtures_data = fixtures_data.drop('stats', axis=1)\n",
    "    fixtures_data = fixtures_data[fixtures_data['started'] != True]\n",
    "    # fixtures_data.to_csv('../data/fixtures_test_all.csv')\n",
    "    fixtures_data = fixtures_data[fixtures_data['started'] == False]\n",
    "    fixtures_data['gw'] = fixtures_data['event'].astype(int)\n",
    "    # fixtures_data['datetime'] = fixtures_data['kickoff_time'].astype('datetime64[ns]')\n",
    "    fixtures_data['kickoff_time'] = pd.to_datetime(fixtures_data['kickoff_time'])\n",
    "    fixtures_data['datetime'] = fixtures_data['kickoff_time'].dt.tz_convert('UTC').dt.tz_localize(None)\n",
    "    fixtures_data['date_str'] = fixtures_data['datetime'].dt.strftime('%Y-%m-%d')\n",
    "    fixtures_data['time_str'] = fixtures_data['datetime'].dt.strftime('%H:%M')\n",
    "    # fixtures_data['date_str'] = fixtures_data['kickoff_time'].str[:10]\n",
    "    # fixtures_data['time_str'] = fixtures_data['kickoff_time'].str[-9:-4]\n",
    "    fixtures_data = pd.merge(fixtures_data, team_data, left_on='team_a', right_on='team_id', how='left').rename(columns={\"short_name\": \"team_a_name\", \"team_id\": \"team_a_id\"})\n",
    "    fixtures_data = pd.merge(fixtures_data, team_data, left_on='team_h', right_on='team_id', how='left').rename(columns={\"short_name\": \"team_h_name\", \"team_id\": \"team_h_id\"})\n",
    "\n",
    "    # Add customized fixtures to fixtures table\n",
    "    fixtures_data.loc[:,'customized'] = False\n",
    "    fixtures_data['custom_dates'] = [[] for _ in range(len(fixtures_data))]\n",
    "    fixtures_data['custom_probs'] = [[] for _ in range(len(fixtures_data))]\n",
    "    if custom_fixtures is not None:\n",
    "        custom_fixtures['added_to_ticker'] = False\n",
    "        for index, row in custom_fixtures.iterrows():\n",
    "            h = custom_fixtures.loc[index,'home_team']\n",
    "            a = custom_fixtures.loc[index,'away_team']\n",
    "            listy = fixtures_data.index[(fixtures_data['team_h_name'] == h) & (fixtures_data['team_a_name'] == a)].to_list()\n",
    "            # if the fixture to be added isn't in the fixtures to be played, add it\n",
    "            if listy != []:\n",
    "                i = listy[0]\n",
    "                fixtures_data.at[i, 'customized'] = True\n",
    "                fixtures_data.at[i, 'custom_dates'] = custom_fixtures.loc[index,'dates']\n",
    "                fixtures_data.at[i, 'custom_probs'] = custom_fixtures.loc[index,'probabilities']\n",
    "                custom_fixtures.at[index, 'added_to_ticker'] = True\n",
    "\n",
    "    # Drop rows not in gameweek range\n",
    "    if gw_range is not None:\n",
    "        mask = fixtures_data['gw'].isin(gw_range)\n",
    "        fixtures_data = fixtures_data[mask]\n",
    "\n",
    "    # Generate ticker\n",
    "    natural_fix_dates = sorted(fixtures_data['date_str'].unique())\n",
    "    custom_fix_dates = []\n",
    "    if custom_fixtures is not None:\n",
    "        for i, x in custom_fixtures.iterrows():\n",
    "            custom_fix_dates += (custom_fixtures.loc[i, 'dates'])\n",
    "    unique_dates = sorted(natural_fix_dates + custom_fix_dates)\n",
    "    unique_dates = sorted(list(set(unique_dates)))\n",
    "    team_fixtures = team_data.assign(**dict.fromkeys(unique_dates, ''))\n",
    "    old_date = None\n",
    "    old_datetime = None\n",
    "    for index, row in fixtures_data.iterrows():\n",
    "        new_date = row['date_str']\n",
    "        new_datetime = row['datetime']\n",
    "        away_team = row['team_a_name']\n",
    "        home_team = row['team_h_name'].lower()\n",
    "        if old_date != new_date or (row['datetime'] == old_datetime and first_fix):\n",
    "            away_team += '!'\n",
    "            home_team += '!'\n",
    "            first_fix = True\n",
    "        else:\n",
    "            first_fix = False\n",
    "        team_fixtures.loc[team_fixtures['short_name'] == row['team_h_name'], row['date_str']] = away_team\n",
    "        team_fixtures.loc[team_fixtures['short_name'] == row['team_a_name'], row['date_str']] = home_team\n",
    "        old_date = new_date\n",
    "        old_datetime = new_datetime\n",
    "    copied_natural_fixtures = team_fixtures.copy()\n",
    "    # Add the custom fixtures to the ticker, deleting their 'natural' placement\n",
    "    # NB: only fixtures that have yet to be played can be added\n",
    "    if custom_fixtures is not None:\n",
    "        for index, row in fixtures_data.iterrows():\n",
    "            if row['customized']:\n",
    "                team_fixtures.loc[team_fixtures['short_name'] == row['team_h_name'], row['date_str']] = ''\n",
    "                team_fixtures.loc[team_fixtures['short_name'] == row['team_a_name'], row['date_str']] = ''\n",
    "                for i, x in enumerate(row['custom_probs']):\n",
    "                    if x == 1:\n",
    "                        prob_str = ''\n",
    "                    elif x == 0:\n",
    "                        break\n",
    "                    else:\n",
    "                        prob_str = '*' + str(int(x*100)) + '%' \n",
    "                    date = row['custom_dates'][i]      \n",
    "                    away_team = row['team_a_name'] + '!' + prob_str\n",
    "                    home_team = row['team_h_name'].lower() + '!' + prob_str\n",
    "                    if team_fixtures.loc[team_fixtures['short_name'] == row['team_h_name'], date].to_list()[0] != '':\n",
    "                        away_team = '\\n' + away_team\n",
    "                    if team_fixtures.loc[team_fixtures['short_name'] == row['team_a_name'], date].to_list()[0] != '':\n",
    "                        home_team = '\\n' + home_team\n",
    "                    team_fixtures.loc[team_fixtures['short_name'] == row['team_h_name'], date] += away_team\n",
    "                    team_fixtures.loc[team_fixtures['short_name'] == row['team_a_name'], date] += home_team\n",
    "        # Add those fixtures which aren't included in the natural fixtures\n",
    "        if False in custom_fixtures['added_to_ticker'].tolist():\n",
    "            extra_custom_fixtures = custom_fixtures.loc[custom_fixtures['added_to_ticker'] == False]\n",
    "            for index, row in extra_custom_fixtures.iterrows():\n",
    "                for i, x in enumerate(row['probabilities']):\n",
    "                    if x == 1:\n",
    "                        prob_str = ''\n",
    "                    else:\n",
    "                        prob_str = '*' + str(int(x*100)) + '%' \n",
    "                    date = row['dates'][i]      \n",
    "                    away_team = row['away_team'] + '!' + prob_str\n",
    "                    home_team = row['home_team'].lower() + '!' + prob_str\n",
    "                    if team_fixtures.loc[team_fixtures['short_name'] == row.loc['home_team'], date].to_list() != []:\n",
    "                        if team_fixtures.loc[team_fixtures['short_name'] == row.loc['home_team'], date].to_list()[0] != '':\n",
    "                            away_team = '\\n' + away_team\n",
    "                    if team_fixtures.loc[team_fixtures['short_name'] == row.loc['away_team'], date].to_list() != []:\n",
    "                        if team_fixtures.loc[team_fixtures['short_name'] == row.loc['away_team'], date].to_list()[0] != '':\n",
    "                            home_team = '\\n' + home_team\n",
    "                    prev1 = team_fixtures.loc[team_fixtures['short_name'] == row.loc['home_team'], date] + away_team\n",
    "                    prev2 = team_fixtures.loc[team_fixtures['short_name'] == row.loc['away_team'], date] + home_team\n",
    "                    team_fixtures.loc[team_fixtures['short_name'] == row.loc['home_team'], date] = prev1\n",
    "                    team_fixtures.loc[team_fixtures['short_name'] == row.loc['away_team'], date] = prev2\n",
    "                    custom_fixtures.loc[index, 'added_to_ticker'] = True\n",
    "\n",
    "    # Generate matchday mapping to sky gw, fpl gw, date, and day of week\n",
    "    weekdays = []\n",
    "    matchdays = []\n",
    "    sky_gw_list = []\n",
    "    fpl_gw_list = []\n",
    "    sky_gw_df = pd.read_csv('../data/sky_gw_starts_2324.csv')\n",
    "    fpl_gw_df = pd.read_csv('../data/fpl_gw_starts_2324.csv')\n",
    "    sky_gw_date = sky_gw_df.loc[0,'start_date']\n",
    "    fpl_gw_date = fpl_gw_df.loc[0,'start_date']\n",
    "    fpl_gw_index = 0\n",
    "    sky_gw_index = 0\n",
    "    # loop through matchdays\n",
    "    for i, x in enumerate(unique_dates):\n",
    "        new_day = str(datetime.strptime(unique_dates[i], '%Y-%m-%d').date().weekday())\n",
    "        weekdays.append(new_day)\n",
    "        matchdays.append(i+1)\n",
    "        # while the date of the current matchday is later than that of the proposed sky gw, proceed to the date of the next sky gw\n",
    "        while x >= sky_gw_date:\n",
    "            broken = False\n",
    "            if sky_gw_index > len(sky_gw_df)-1:\n",
    "                broken = True\n",
    "                break\n",
    "            sky_gw_index += 1\n",
    "            sky_gw_date = sky_gw_df.loc[sky_gw_index-1, 'start_date']\n",
    "        if broken:\n",
    "            sky_gw = sky_gw + 1\n",
    "        else:\n",
    "            sky_gw = sky_gw_df.loc[sky_gw_index-1, 'gameweek']-1\n",
    "        sky_gw_list.append(sky_gw)\n",
    "        # while the date of the current matchday is later than that of the proposed fpl gw, proceed to the date of the next fpl gw\n",
    "        while x >= fpl_gw_date:\n",
    "            broken = False\n",
    "            if fpl_gw_index > len(fpl_gw_df)-1:\n",
    "                broken = True\n",
    "                break\n",
    "            fpl_gw_index += 1\n",
    "            fpl_gw_date = fpl_gw_df.loc[fpl_gw_index-1, 'start_date']\n",
    "        if broken:\n",
    "            fpl_gw = fpl_gw + 1\n",
    "        else:\n",
    "            fpl_gw = fpl_gw_df.loc[fpl_gw_index-1, 'gameweek']-1\n",
    "        fpl_gw_list.append(fpl_gw)\n",
    "    data = {'unique_dates': unique_dates,\n",
    "            'weekday': weekdays,\n",
    "            'matchday': matchdays,\n",
    "            'sky_gw': sky_gw_list,\n",
    "            'fpl_gw': fpl_gw_list\n",
    "            }\n",
    "    md_map = pd.DataFrame(data)\n",
    "    date_0 = md_map.loc[0,'unique_dates']\n",
    "    date_0 = datetime.strptime(date_0, '%Y-%m-%d').date()\n",
    "    for i, col in md_map.iterrows():\n",
    "        date_1 = md_map.loc[i,'unique_dates']\n",
    "        date_1 = datetime.strptime(date_1, '%Y-%m-%d').date()\n",
    "        delta = int((date_1 - date_0).days)\n",
    "        md_map.loc[i,'days_elapsed'] = delta\n",
    "\n",
    "    # Generate dataframes for all possible fixture permutations for stochastic optimization, assuming all fixtures are independent\n",
    "    if generate_all_dataframes and extra_fixtures is not None:\n",
    "        uncertain_fixtures = extra_fixtures.drop(extra_fixtures[extra_fixtures.probability == 1].index)\n",
    "        my_list = uncertain_fixtures.probability.tolist()\n",
    "        # Assume all fixtures are independent\n",
    "        n_uncert_fix = len(my_list)\n",
    "        number_of_permutations = 2**(n_uncert_fix)\n",
    "        fix_permutation_dict = {}\n",
    "        for i in range(number_of_permutations):\n",
    "            fixture_key = f'permutation_{i+1}'\n",
    "            permutation_string = format(i, f'0{n_uncert_fix}b')\n",
    "            df = copied_natural_fixtures.copy()\n",
    "            likelihood = 1\n",
    "            for i, x in enumerate(permutation_string):\n",
    "                if bool(int(x)):\n",
    "                    away_team = uncertain_fixtures.loc[i,'away_team']\n",
    "                    home_team = uncertain_fixtures.loc[i,'home_team']\n",
    "                    df.loc[df['short_name'] == home_team, uncertain_fixtures.loc[i,'date']] = away_team\n",
    "                    df.loc[df['short_name'] == away_team, uncertain_fixtures.loc[i,'date']] = home_team.lower()\n",
    "                    likelihood = likelihood * uncertain_fixtures.loc[i,'probability']\n",
    "                else:\n",
    "                    likelihood = likelihood * (1-uncertain_fixtures.loc[i,'probability'])\n",
    "            fix_permutation_dict[fixture_key] = {'df': df, 'likelihood': likelihood}\n",
    "    else:\n",
    "        fix_permutation_dict = None\n",
    "\n",
    "    fixtures_df = team_fixtures.copy()\n",
    "\n",
    "    # Drop excluded teams\n",
    "    if exclude_teams is not None:\n",
    "        for i in exclude_teams:\n",
    "            team_fixtures = team_fixtures[team_fixtures.short_name != i]\n",
    "\n",
    "    # Add gameweek superheader\n",
    "    date_to_gw = fixtures_data[['date_str','gw']].drop_duplicates()\n",
    "    headers = list(team_fixtures.columns.values)\n",
    "    sky_gw_header = []\n",
    "    fpl_gw_header = []\n",
    "    for i in headers:\n",
    "        if i.startswith('20') == False:\n",
    "            j = 'sky_gw'\n",
    "            k = 'fpl_gw'\n",
    "        else:\n",
    "            sky_gw = md_map.loc[md_map['unique_dates']==i,'sky_gw'].values[0]\n",
    "            fpl_gw = md_map.loc[md_map['unique_dates']==i,'fpl_gw'].values[0]\n",
    "            j = str(sky_gw)\n",
    "            k = str(fpl_gw)\n",
    "        sky_gw_header.append(j)\n",
    "        fpl_gw_header.append(k)\n",
    "    md_header = []\n",
    "    for i in headers:\n",
    "        if i.startswith('20') == False:\n",
    "            j = 'matchday'\n",
    "        else:\n",
    "            md = md_map.loc[md_map['unique_dates']==i,'matchday'].values[0]\n",
    "            j = str(md)\n",
    "        md_header.append(j)\n",
    "    team_fixtures.columns=[sky_gw_header, fpl_gw_header, md_header, headers]\n",
    "\n",
    "\n",
    "    formatted_fixtures = team_fixtures.copy()\n",
    "    # Make color map dictionary and function\n",
    "    color_ts = team_priors[['short_team','h_gd', 'a_gd']].copy()\n",
    "    min_gd = min(color_ts['h_gd'].values.tolist() + color_ts['a_gd'].values.tolist())*2.3\n",
    "    max_gd = max(color_ts['h_gd'].values.tolist() + color_ts['a_gd'].values.tolist())#*1.8\n",
    "    norm = matplotlib.colors.Normalize(vmin=min_gd, vmax=max_gd, clip=True)\n",
    "    mapper = plt.cm.ScalarMappable(norm=norm, cmap=plt.cm.viridis_r)\n",
    "    color_ts['h_gd_color'] = color_ts['h_gd'].apply(lambda x: mcolors.to_hex(mapper.to_rgba(x)))\n",
    "    color_ts['a_gd_color'] = color_ts['a_gd'].apply(lambda x: mcolors.to_hex(mapper.to_rgba(x)))\n",
    "    h_teams = color_ts['short_team'].values.tolist()\n",
    "    a_teams = [team.lower() for team in h_teams]\n",
    "    teams = h_teams + a_teams\n",
    "    team_gd = color_ts['a_gd_color'].values.tolist() + color_ts['h_gd_color'].values.tolist()\n",
    "    color_dict = {teams[i]: team_gd[i] for i in range(len(teams))}\n",
    "    def color_col(col, pattern_map, default=''):\n",
    "        return np.select(\n",
    "            [col.str.contains(k, na=False) for k in pattern_map.keys()],\n",
    "            [f'background-color: {v}' for v in pattern_map.values()],\n",
    "            default=default\n",
    "        ).astype(str)\n",
    "    # Apply styles\n",
    "    formatted_fixtures = formatted_fixtures.style.apply(color_col,\n",
    "                                                pattern_map=color_dict\n",
    "                                                , subset=team_fixtures.columns[2:]\n",
    "                                                )\n",
    "    formatted_fixtures = formatted_fixtures.set_table_styles([\n",
    "                        {'selector': 'th.col_heading', 'props': 'text-align: left;'},\n",
    "                        {'selector': 'th.col_heading.level0', 'props': 'font-size: 1em;'},\n",
    "                        {'selector': 'td', 'props': 'text-align: center; font-weight: bold;'},\n",
    "                    ], overwrite=False)\n",
    "    formatted_fixtures = formatted_fixtures.set_properties(**{'color': 'white'},subset=(formatted_fixtures.columns[2:]))\n",
    "\n",
    "    return {'formatted_fixtures': formatted_fixtures, 'fixtures_data': fixtures_df, 'matchday_map': md_map, 'fix_permutation_dict': fix_permutation_dict, 'unformatted_fixtures': team_fixtures}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Functions\n",
    "\n",
    "Generate dataframe of expected points values for a specified period, based on prior team and player level data. Calls fixture fixture generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_team_data_gen():\n",
    "\n",
    "    team_data = pd.read_csv('../data/team_priors.csv', index_col=0)\n",
    "\n",
    "    return team_data\n",
    "\n",
    "def prior_player_data_gen(team_data, dynamic_pens):\n",
    "    \n",
    "    prior_player_data = pd.read_csv('../data/prior_player_data.csv')\n",
    "    pen_taker_override = pd.read_csv('../data/pen_taker_override.csv')\n",
    "    for index, row in pen_taker_override.iterrows():\n",
    "        if row['pen_share']==row['pen_share']:\n",
    "            prior_player_data.loc[prior_player_data['sky_id']==row['sky_id'], 'on_pens'] = row['pen_share']\n",
    "            print(str(row['reference_name']) + ' pen share overridden to ' + str(row['pen_share']))\n",
    "\n",
    "    try:\n",
    "        filepath = '../data/fplreview.csv'\n",
    "        fplreview = pd.read_csv(filepath)\n",
    "        fplreview = fplreview.rename(columns={'ID': 'fpl_id'})\n",
    "        review_xmins = True\n",
    "        print(f\"Using minutes from {filepath}\")\n",
    "    except:\n",
    "        review_xmins = False\n",
    "        print(f\"{filepath} not found, using default baseline minutes\") \n",
    "\n",
    "    gw_min_list = []\n",
    "    if review_xmins:\n",
    "        # Get gw x_mins from fplreview file, and overwite\n",
    "        for element in list(fplreview.columns.values):\n",
    "            if '_xMins' in element:\n",
    "                gw_min_list.append(element)\n",
    "        for element in list(prior_player_data.columns.values):\n",
    "            if element in gw_min_list:\n",
    "                prior_player_data = prior_player_data.drop(columns = [element])\n",
    "        prior_player_data = pd.merge(prior_player_data, fplreview.loc[:,['fpl_id'] + gw_min_list], on=['fpl_id'], how='inner')\n",
    "    else:\n",
    "        for gw in range(1,39):\n",
    "            gw_min_list.append(str(gw)+'_xMins')\n",
    "            prior_player_data[str(gw)+'_xMins'] = prior_player_data['bl_xmin']\n",
    "\n",
    "    # NEW: allocate pen share on a week-by-week basis based on xmins and on_pens parameter\n",
    "    if dynamic_pens:\n",
    "    # print(gw_min_list)\n",
    "        for team in prior_player_data['short_team'].unique():\n",
    "            prior_player_data_team_subset = prior_player_data.copy()\n",
    "            prior_player_data_team_subset = prior_player_data_team_subset[prior_player_data_team_subset['short_team']==team].sort_values(by=['on_pens'], ascending=[False])\n",
    "            prior_player_data_team_subset = prior_player_data_team_subset[prior_player_data_team_subset['on_pens']>0]\n",
    "            prior_player_data_team_subset['on_pens'] = prior_player_data_team_subset['on_pens'] / prior_player_data_team_subset['on_pens'].sum()\n",
    "            for gw_mins in gw_min_list:\n",
    "                for index, row in prior_player_data_team_subset.copy().iterrows():\n",
    "                    prior_player_data_team_subset.at[index, str(gw_mins)+'_pen_claim'] = row['on_pens']* ((row[str(gw_mins)])/95)**3\n",
    "                pen_claim_total = max(prior_player_data_team_subset[str(gw_mins)+'_pen_claim'].sum(), 0.01)\n",
    "                for index, row in prior_player_data_team_subset.copy().iterrows():\n",
    "                    pen_amount = (row[str(gw_mins)+'_pen_claim'] / pen_claim_total)\n",
    "                    # pen_amount = pen_amount.item()\n",
    "                    prior_player_data_team_subset.loc[index, str(gw_mins)+'_pen_share'] = pen_amount\n",
    "                    prior_player_data.loc[index, str(gw_mins)+'_pen_share'] = pen_amount\n",
    "            # display(prior_player_data_team_subset[['fbref_player', 'short_team', 'on_pens', '21_xMins', '21_xMins_pen_share', '21_xMins_pen_claim', '26_xMins', '26_xMins_pen_share', '26_xMins_pen_claim']])\n",
    "        prior_player_data.fillna(0, inplace = True)\n",
    "\n",
    "    return {'prior_player_data':prior_player_data, 'review_xmins':review_xmins, 'gw_min_list':gw_min_list}\n",
    "\n",
    "def sky_xP_calc(sky_id, opp_team, prior_player_data, team_data, xMins, xP_breakdown=False, review_xmins=True, pen_share_gw=None):\n",
    "    player_data = prior_player_data.loc[prior_player_data['sky_id'] == sky_id].reset_index()\n",
    "    own_team = player_data.loc[0, 'short_team']\n",
    "    own_team_data = team_data.loc[team_data['short_team'] == own_team].reset_index()\n",
    "    opp_data = team_data.loc[team_data['short_team'] == opp_team.upper()].reset_index()\n",
    "    Pos = player_data.loc[0, 'sky_pos']\n",
    "    if opp_team.isupper() == True:\n",
    "        home_adv = own_team_data.loc[0, 'home_adv_g']\n",
    "        home_adv_pass = own_team_data.loc[0, 'home_adv_pass']\n",
    "    elif opp_team.islower() == True:\n",
    "        home_adv = 1/own_team_data.loc[0, 'home_adv_g']\n",
    "        home_adv_pass = 1/own_team_data.loc[0, 'home_adv_pass']\n",
    "    else:\n",
    "        home_adv = 1\n",
    "        home_adv_pass = 1\n",
    "    if Pos == 'GK':\n",
    "        k_G = 7\n",
    "        k_CS = 7\n",
    "        k_2GC = -1\n",
    "    elif Pos == 'DEF':\n",
    "        k_G = 7\n",
    "        k_CS = 5\n",
    "        k_2GC = -1\n",
    "    elif Pos == 'MID':\n",
    "        k_G = 6\n",
    "        k_CS = 0\n",
    "        k_2GC = 0\n",
    "    else:\n",
    "        k_G = 5\n",
    "        k_CS = 0\n",
    "        k_2GC = 0\n",
    "    k_Start = 2\n",
    "    k_Sub = 1\n",
    "    k_A = 3\n",
    "    k_PenSv = 5\n",
    "    k_PenMiss = -3\n",
    "    k_Yc = -1\n",
    "    k_Rc = -3\n",
    "    k_OG = -2\n",
    "    k_T1 = 2\n",
    "    k_T2 = 3\n",
    "    x_90s = xMins/90\n",
    "    if review_xmins:\n",
    "        x_95s = xMins/95\n",
    "        p_start = (0.5)*(0.5 + np.cbrt((x_95s-0.5)/4)) + (0.5)*x_95s\n",
    "    else:\n",
    "        p_start = (0.5)*(0.5 + np.cbrt((x_90s-0.5)/4)) + (0.5)*x_90s\n",
    "    StartxP = k_Start * p_start\n",
    "    SubxP = k_Sub * (1-p_start) * x_90s\n",
    "    GxP = k_G * player_data.loc[0, 'bl_npxg'] * opp_data.loc[0, 'bl_xg_against_k'] * x_90s * home_adv * player_data.loc[0, 'fin_skill']\n",
    "    AxP = k_A * player_data.loc[0, 'bl_a'] * opp_data.loc[0, 'bl_g_against_k'] * x_90s * home_adv\n",
    "    OGxP = k_OG * player_data.loc[0, 'bl_og'] * opp_data.loc[0, 'bl_og_against_k'] * x_90s / home_adv\n",
    "\n",
    "    if pen_share_gw is not None:\n",
    "        # NEW: Pen share as defined here has already been scaled according to xMins \n",
    "        PenScorexP = k_G * pen_share_gw * (player_data.loc[0, 'fin_skill'] * 0.78) * own_team_data.loc[0, 'bl_pk_att_for'] * opp_data.loc[0, 'bl_pk_att_against_k'] * home_adv\n",
    "        PenMissxP = k_PenMiss * pen_share_gw * (1-player_data.loc[0, 'fin_skill'] * 0.78) * own_team_data.loc[0, 'bl_pk_att_for'] * opp_data.loc[0, 'bl_pk_att_against_k'] * home_adv\n",
    "    elif player_data.loc[0, 'on_pens'] > 0:\n",
    "        PenScorexP = k_G * player_data.loc[0, 'on_pens'] * (player_data.loc[0, 'fin_skill'] * 0.78) * own_team_data.loc[0, 'bl_pk_att_for'] * opp_data.loc[0, 'bl_pk_att_against_k'] * x_90s * home_adv\n",
    "        PenMissxP = k_PenMiss * player_data.loc[0, 'on_pens'] * (1-player_data.loc[0, 'fin_skill'] * 0.78) * own_team_data.loc[0, 'bl_pk_att_for'] * opp_data.loc[0, 'bl_pk_att_against_k'] * x_90s * home_adv\n",
    "    else:\n",
    "        PenScorexP, PenMissxP = 0, 0\n",
    "        \n",
    "    if Pos == 'GK':\n",
    "        PenSvxP = k_PenSv * own_team_data.loc[0, 'bl_pk_att_against_k'] * 0.176 * opp_data.loc[0, 'bl_pk_att_for'] * x_90s / home_adv\n",
    "        mu_sv = player_data.loc[0, 'bl_sv_per_sot'] * opp_data.loc[0, 'bl_sot_for'] * own_team_data.loc[0, 'bl_sot_against_k']  * x_90s / home_adv\n",
    "        T1SvxP = k_T1 * (poisson.cdf(k=4, mu=mu_sv) - poisson.cdf(k=2, mu=mu_sv))\n",
    "        T2SvxP = k_T2 * (1 - poisson.cdf(k=4, mu=mu_sv))\n",
    "    else:\n",
    "        PenSvxP = T1SvxP = T2SvxP = 0\n",
    "    YcxP = k_Yc * player_data.loc[0, 'bl_yc'] * opp_data.loc[0, 'bl_yc_against_k'] * x_90s\n",
    "    RcxP = k_Rc * player_data.loc[0, 'bl_rc'] * opp_data.loc[0, 'bl_yc_against_k'] * x_90s\n",
    "\n",
    "    mu_gc = own_team_data.loc[0, 'bl_g_against_k'] * opp_data.loc[0, 'bl_g_for'] / home_adv\n",
    "    CSxP = k_CS * poisson.cdf(k=0, mu=mu_gc) * p_start * player_data.loc[0, 'bl_p_60_given_start']\n",
    "    GCxP = k_2GC * ((1 - poisson.cdf(k=1, mu=mu_gc*x_90s)) + (1 - poisson.cdf(k=2, mu=mu_gc*x_90s)) + (1 - poisson.cdf(k=3, mu=mu_gc*x_90s)) + (1 - poisson.cdf(k=4, mu=mu_gc*x_90s)) + (1 - poisson.cdf(k=5, mu=mu_gc*x_90s)))\n",
    "\n",
    "    mu_tack = player_data.loc[0, 'bl_tack'] * opp_data.loc[0, 'bl_tack_against_k'] * x_90s\n",
    "    T1TackxP = k_T1 * (poisson.cdf(k=4, mu=mu_tack) - poisson.cdf(k=3, mu=mu_tack))\n",
    "    T2TackxP = k_T2 * (1 - poisson.cdf(k=4, mu=mu_tack))\n",
    "    av_pass = player_data.loc[0, 'bl_pass'] * opp_data.loc[0, 'bl_pass_against_k'] * x_90s * home_adv_pass\n",
    "    T1PassxP = k_T1 * (norm.cdf(x=69, loc=av_pass, scale=av_pass*0.405) - norm.cdf(x=59, loc=av_pass, scale=av_pass*0.405))\n",
    "    T2PassxP = k_T2 * (1 - norm.cdf(x=69, loc=av_pass, scale=av_pass*0.405))\n",
    "    mu_sot = player_data.loc[0, 'bl_sot'] * opp_data.loc[0, 'bl_sot_against_k'] * x_90s * home_adv\n",
    "    T1SOTxP = k_T1 * (poisson.cdf(k=2, mu=mu_sot) - poisson.cdf(k=1, mu=mu_sot))\n",
    "    T2SOTxP = k_T2 * (1 - poisson.cdf(k=2, mu=mu_sot))\n",
    "    xP = GxP + AxP + OGxP + PenScorexP + PenMissxP + PenSvxP + StartxP + SubxP + YcxP + RcxP + CSxP + GCxP + T1SvxP + T1TackxP + T1PassxP + T1SOTxP + T2SvxP + T2TackxP + T2PassxP + T2SOTxP\n",
    "    if xP_breakdown == True:\n",
    "        xP_breakdown = {'Actions': ['Start', 'Sub', 'Goal', 'Assist', 'Own Goal', 'Pen Goal', 'Pen Miss', 'Pen Save', 'Yellow Card', 'Red Card', 'Clean Sheet', 'Goal Conceded',\n",
    "                                    'Tier 1 Save', 'Tier 1 Tackle', 'Tier 1 Pass', 'Tier 1 SOT', 'Tier 2 Save', 'Tier 2 Tackle', 'Tier 2 Pass', 'Tier 2 SOT', 'TOTAL'],\n",
    "                        'xP': [StartxP, SubxP, GxP, AxP, OGxP, PenScorexP, PenMissxP, PenSvxP, YcxP, RcxP, CSxP, GCxP, T1SvxP, T1TackxP, T1PassxP, T1SOTxP, T2SvxP, T2TackxP, T2PassxP, T2SOTxP, xP]\n",
    "                        }\n",
    "        xP_breakdown = pd.DataFrame(xP_breakdown)\n",
    "        xP_breakdown = xP_breakdown.drop(xP_breakdown[xP_breakdown.xP == 0].index)\n",
    "        xP_breakdown.xP = round(xP_breakdown.xP,2)\n",
    "    return {'xP': xP, 'xP_breakdown': xP_breakdown}\n",
    "\n",
    "def horizontal_df_layout(dfs):\n",
    "    html = '<div style=\"display:flex\">'\n",
    "    for df in dfs:\n",
    "        html += '<div style=\"margin-right: 32px\">'\n",
    "        html += df.to_html()\n",
    "        html += '</div>'\n",
    "    html += '</div>'\n",
    "    display(HTML(html))\n",
    "\n",
    "def generate_model_output(first_md=1, last_md=14, filename_suffix=None, custom_fixtures=None, teamsheet_boost=None, dynamic_pens=False):\n",
    "    schedule_name = 'sky_schedule'\n",
    "    if filename_suffix is not None:\n",
    "        schedule_name += filename_suffix\n",
    "    \n",
    "    if custom_fixtures is not None:\n",
    "        r = generate_ticker(custom_fixtures=custom_fixtures)\n",
    "    else:\n",
    "        r = generate_ticker()\n",
    "    md_map_2 = r['matchday_map']\n",
    "    sky_schedule_2 = r['fixtures_data']\n",
    "    formatted_fixtures = r['formatted_fixtures']\n",
    "    unformatted_fixtures = r['unformatted_fixtures']\n",
    "    headers = []\n",
    "    for i, x in enumerate(sky_schedule_2.columns.values.tolist()):\n",
    "        if x in md_map_2['unique_dates'].tolist():\n",
    "            h = md_map_2.loc[md_map_2['unique_dates'] == x, 'matchday'].values[0]\n",
    "            h = 'MD ' + str(h)\n",
    "            headers.append(h)\n",
    "        else:\n",
    "            headers.append(x)\n",
    "    sky_schedule_2.columns = headers\n",
    "\n",
    "    if str(last_md) == last_md:\n",
    "        if last_md > md_map_2['unique_dates'].tolist()[-1]:\n",
    "            last_md = md_map_2.loc[len(md_map_2)-1, 'matchday']\n",
    "        else:\n",
    "            for i, x in enumerate(md_map_2['unique_dates'].tolist()):\n",
    "                if last_md < x:\n",
    "                    last_md = md_map_2.loc[i, 'matchday'] - 1\n",
    "                    break\n",
    "    if str(last_md) == last_md:\n",
    "        last_md = md_map_2.loc[len(md_map_2)-1, 'matchday']\n",
    "\n",
    "    matchdays = range(first_md,last_md+1)\n",
    "    team_data = prior_team_data_gen()\n",
    "    player_data_results = prior_player_data_gen(team_data=team_data, dynamic_pens=dynamic_pens)\n",
    "    prior_player_data = player_data_results['prior_player_data']\n",
    "    review_xmins = player_data_results['review_xmins']\n",
    "\n",
    "    fpd = pd.merge(prior_player_data, sky_schedule_2, left_on='short_team', right_on='short_name', how='left')\n",
    "    \n",
    "    #COME BACK\n",
    "    fixture_player_data = fpd.copy()\n",
    "    # fixture_player_data = fpd\n",
    "\n",
    "    for i in range(first_md, last_md+1):\n",
    "        gw = md_map_2.loc[md_map_2['matchday']==i, 'fpl_gw'].values[0]\n",
    "        if f'{gw}_xMins' not in fixture_player_data.columns:\n",
    "            if f'{gw-1}_xMins' not in fixture_player_data.columns:\n",
    "                fixture_player_data[f'{gw}_xMins'] = fixture_player_data[f'{gw+1}_xMins']\n",
    "            else:\n",
    "                fixture_player_data[f'{gw}_xMins'] = fixture_player_data[f'{gw-1}_xMins']\n",
    "        fixture_player_data[f'MD {i} Game'] = fixture_player_data[f'MD {i}'].str.len() > 1.5\n",
    "        fixture_player_data[f'MD_{i}_xMins'] = fixture_player_data[f'{gw}_xMins'] * fixture_player_data[f'MD {i} Game']\n",
    "\n",
    "        # NEW: allocate pen share on a week-by-week basis based on xmins and on_pens parameter\n",
    "        if dynamic_pens:\n",
    "            if f'{gw}_xMins_pen_share' not in fixture_player_data.columns:\n",
    "                if f'{gw-1}_xMins_pen_share' not in fixture_player_data.columns:\n",
    "                    fixture_player_data[f'{gw}_xMins_pen_share'] = fixture_player_data[f'{gw+1}_xMins_pen_share']\n",
    "                else:\n",
    "                    fixture_player_data[f'{gw}_xMins_pen_share'] = fixture_player_data[f'{gw-1}_xMins_pen_share']\n",
    "            # fixture_player_data[f'MD {i} Game'] = fixture_player_data[f'MD {i}'].str.len() > 1.5\n",
    "            fixture_player_data[f'MD_{i}_xMins_pen_share'] = fixture_player_data[f'{gw}_xMins_pen_share'] * fixture_player_data[f'MD {i} Game']\n",
    "\n",
    "    players = fixture_player_data.index.tolist()\n",
    "    for p in players:\n",
    "        SKY_ID = fixture_player_data.loc[p, 'sky_id']\n",
    "        for m in matchdays:\n",
    "            xMins = fixture_player_data.loc[p, f'MD_{m}_xMins']\n",
    "            if xMins < 5:\n",
    "                xP = 0\n",
    "            else:\n",
    "                if dynamic_pens:\n",
    "                    pen_share_gw = fixture_player_data.loc[p, f'MD_{m}_xMins_pen_share']\n",
    "                else:\n",
    "                    pen_share_gw = None\n",
    "                fix_string = fixture_player_data.loc[p, f'MD {m}']\n",
    "                if '\\n' in fix_string:\n",
    "                    xP = 0\n",
    "                    fix_list = fix_string.split('\\n')\n",
    "                    for i, x in enumerate(fix_list):\n",
    "                        r = sky_xP_calc(SKY_ID, x[:3], fixture_player_data, team_data, xMins, xP_breakdown=False, review_xmins=review_xmins, pen_share_gw=pen_share_gw)\n",
    "                        sub_xP = r['xP']\n",
    "                        if any(c.isdigit() for c in x):\n",
    "                            sub_xP = sub_xP * int(''.join(filter(str.isdigit, x))) / 100\n",
    "                        xP += sub_xP\n",
    "                else:\n",
    "                    r = sky_xP_calc(SKY_ID, fixture_player_data.loc[p, f'MD {m}'][:3], fixture_player_data, team_data, xMins, xP_breakdown=False, review_xmins=review_xmins, pen_share_gw=pen_share_gw)\n",
    "                    xP = r['xP']\n",
    "                    if any(c.isdigit() for c in fix_string):\n",
    "                        xP = xP * int(''.join(filter(str.isdigit, fix_string))) / 100\n",
    "                if teamsheet_boost is not None:\n",
    "                    if '!' in fix_string:\n",
    "                        xP = xP * (1+teamsheet_boost)\n",
    "            fixture_player_data.loc[p, f'MD_{m}_Pts'] = round(xP, 2)\n",
    "    skymodel_output = pd.concat([fixture_player_data.loc[:,['sky_id', 'fbref_player', 'short_team', 'sky_pos', 'sky_value']],\n",
    "                                    fixture_player_data.iloc[:,-(last_md-first_md+1):]],axis = 1)\n",
    "    skymodel_output['Total_Pts'] = skymodel_output.iloc[:, -(last_md-first_md+1):].sum(axis=1)\n",
    "    skymodel_output = skymodel_output.fillna(0)\n",
    "    filename = 'skymodel_output'\n",
    "    if filename_suffix is not None:\n",
    "        filename += filename_suffix\n",
    "    skymodel_output.to_csv(f'../data/{filename}.csv')\n",
    "    md_map_2.to_csv(f'../data/md_map.csv', index = False)\n",
    "\n",
    "    # archive model outputs\n",
    "    add_to_archive = True\n",
    "    gw = md_map_2.loc[md_map_2['matchday']==first_md, 'fpl_gw'].values[0]\n",
    "    md_map_filepath = f'../data/past_model_outputs/md_map_fplgw{gw}.csv'\n",
    "    my_file = Path(md_map_filepath)\n",
    "    if my_file.is_file():\n",
    "        md_map_old = pd.read_csv(md_map_filepath)\n",
    "        md_map_2['weekday'] = md_map_2['weekday'].astype('int')\n",
    "        if not md_map_old.iloc[0].equals(md_map_2.iloc[0]):\n",
    "            add_to_archive = False\n",
    "            print('Note: model outputs generated mid gameweek will not be archived')\n",
    "\n",
    "    if add_to_archive:\n",
    "        skymodel_output.to_csv(f'../data/past_model_outputs/{filename}_fplgw{gw}.csv')\n",
    "        md_map_2.to_csv(f'../data/past_model_outputs/md_map_fplgw{gw}.csv', index = False)\n",
    "        filepath = '../data/fplreview.csv'\n",
    "        my_file = Path(filepath)\n",
    "        if my_file.is_file():\n",
    "            fplreview = pd.read_csv(filepath)\n",
    "            fplreview = fplreview.rename(columns={'ID': 'fpl_id'})\n",
    "            for i in range(40):\n",
    "                if f'{i}_Pts' in fplreview.columns.tolist():\n",
    "                    fplreview = fplreview.drop(f'{i}_Pts', axis=1)\n",
    "            fplreview.to_csv(f'../data/past_model_outputs/review_xmins_fplgw{gw}.csv', index = False)\n",
    "        # prior_player_data.to_csv(f'../data/past_model_outputs/prior_player_data_fplgw{gw}.csv', index = False)\n",
    "        # team_data.to_csv(f'../data/past_model_outputs/team_data_fplgw{gw}.csv', index = False)\n",
    "        print('Model outputs archived')\n",
    "\n",
    "    return {'skymodel_output':skymodel_output, 'formatted_fixtures':formatted_fixtures, 'md_map': md_map_2, 'unformatted_fixtures': unformatted_fixtures}\n",
    "\n",
    "def read_skymodel_output(max_ev_cutoff=0.3, max_ev_per_price_cutoff=0.3, initial_squad=None, flatten_final_matchdays=None):\n",
    "    skymodel_output = pd.read_csv('../data/skymodel_output.csv').set_index('sky_id').fillna(0)\n",
    "\n",
    "    skymodel_output['ev_per_price'] = skymodel_output['Total_Pts'] / skymodel_output['sky_value']\n",
    "    \n",
    "    skymodel_output_unfiltered = skymodel_output.copy()\n",
    "\n",
    "    if initial_squad is None:\n",
    "        initial_squad = []\n",
    "\n",
    "    ev_cutoff = skymodel_output['Total_Pts'].max() * max_ev_cutoff\n",
    "    skymodel_output = skymodel_output[skymodel_output['Total_Pts'] > ev_cutoff]\n",
    "    \n",
    "    ev_per_price_cutoff = skymodel_output['ev_per_price'].max() * max_ev_per_price_cutoff\n",
    "    skymodel_output = skymodel_output[skymodel_output['ev_per_price'] > ev_per_price_cutoff]\n",
    "    removed_players = [i for i in initial_squad if i not in skymodel_output.index.values.tolist()]\n",
    "\n",
    "    for id in removed_players:\n",
    "        player_row = skymodel_output_unfiltered.loc[id, :].values.flatten().tolist()\n",
    "        skymodel_output.loc[id] = player_row\n",
    "\n",
    "    md_map = pd.read_csv('../data/md_map.csv')\n",
    "\n",
    "    return skymodel_output, md_map\n",
    "\n",
    "def read_fpl_kid_model(max_ev_cutoff=0.3, max_ev_per_price_cutoff=0.3):\n",
    "    filepath = '../data/fplkid.csv'\n",
    "    fpl_kid = pd.read_csv(filepath).fillna(0)\n",
    "    fpl_kid = fpl_kid.rename(columns = {'Pos':'sky_pos', 'ID':'sky_id', 'BV':'sky_value'})\n",
    "    fpl_kid['Total_Pts'] = 0\n",
    "    for i in range(200):\n",
    "        fpl_kid = fpl_kid.rename(columns = {f'GD{i}_Pts':f'MD_{i}_Pts',f'GD{i}_xMins':f'MD_{i}_xMins'})\n",
    "        if f'MD_{i}_Pts' in fpl_kid.columns.tolist():\n",
    "            fpl_kid['Total_Pts'] += fpl_kid[f'MD_{i}_Pts']\n",
    "    fpl_kid = fpl_kid.drop(columns=['Name', 'SV', 'Team'])\n",
    "\n",
    "    fpl_kid['sky_pos'] = fpl_kid['sky_pos'].str.replace('G','GK')\n",
    "    fpl_kid['sky_pos'] = fpl_kid['sky_pos'].str.replace('F','FOR')\n",
    "    fpl_kid['sky_pos'] = fpl_kid['sky_pos'].str.replace('D','DEF')\n",
    "    fpl_kid['sky_pos'] = fpl_kid['sky_pos'].str.replace('M','MID')\n",
    "\n",
    "    player_data_merge = pd.read_csv('../data/prior_player_data.csv')\n",
    "    player_data_merge = player_data_merge[['sky_id','fbref_player','short_team']]\n",
    "\n",
    "    fpl_kid = pd.merge(left = fpl_kid, right = player_data_merge, on='sky_id', how='inner')\n",
    "    fpl_kid = fpl_kid.set_index('sky_id')\n",
    "    skymodel_output = fpl_kid.copy()\n",
    "    \n",
    "    ev_cutoff = skymodel_output['Total_Pts'].max() * max_ev_cutoff\n",
    "    skymodel_output = skymodel_output[skymodel_output['Total_Pts'] > ev_cutoff]\n",
    "\n",
    "    skymodel_output['ev_per_price'] = skymodel_output['Total_Pts'] / skymodel_output['sky_value']\n",
    "    ev_per_price_cutoff = skymodel_output['ev_per_price'].max() * max_ev_per_price_cutoff\n",
    "    skymodel_output = skymodel_output[skymodel_output['ev_per_price'] > ev_per_price_cutoff]\n",
    "\n",
    "    md_map = pd.read_csv('../data/md_map.csv')\n",
    "\n",
    "    return skymodel_output, md_map\n",
    "\n",
    "def generate_cap_matrix(last_md = 20, max_ev_diff = 1):\n",
    "    # Read the data from the CSV file\n",
    "    skymodel_output = pd.read_csv('../data/skymodel_output.csv').set_index('sky_id').fillna(0)\n",
    "\n",
    "    # Define the maximum matchday number\n",
    "    md = last_md\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    result_data = []\n",
    "\n",
    "    # Generate values from 0.0 to -1.0 in 0.1 increments\n",
    "    distance_to_cap_values = np.arange(0.0, -max_ev_diff-0.1, -0.1)\n",
    "\n",
    "    # Iterate through the distance_to_cap values\n",
    "    for distance_to_cap in distance_to_cap_values:\n",
    "        # Round the distance_to_cap value to the nearest 0.1\n",
    "        rounded_distance_to_cap = round(distance_to_cap, 1)\n",
    "        \n",
    "        # Create a list to store players for each matchday\n",
    "        players_list = []\n",
    "        \n",
    "        # Iterate through each matchday column\n",
    "        for md_num in range(1, md + 1):\n",
    "            # Calculate the maximum score in the current matchday column for all players\n",
    "            max_score = skymodel_output[f'MD_{md_num}_Pts'].max()\n",
    "            \n",
    "            # Calculate the difference between each player's score and the maximum score\n",
    "            skymodel_output[f'MD_{md_num}_Cap'] = skymodel_output[f'MD_{md_num}_Pts'] - max_score\n",
    "            \n",
    "            # Filter players whose MD_{md}_Cap value matches the rounded_distance_to_cap\n",
    "            players = skymodel_output[skymodel_output[f'MD_{md_num}_Cap'].round(1) == rounded_distance_to_cap]['fbref_player'].tolist()\n",
    "            \n",
    "            # Store the players for the current gameweek in the players_list\n",
    "            players_list.append(players)\n",
    "\n",
    "        # display(players_list)\n",
    "        new_list = []\n",
    "        for p in players_list:\n",
    "            if len(p) == 0:\n",
    "                new_list.append([])\n",
    "            else:\n",
    "                sublist = []\n",
    "                for q in p:\n",
    "                    sublist.append(q.split(' ')[-1])\n",
    "                new_list.append(sublist)\n",
    "        players_list = new_list\n",
    "        # display(players_list)\n",
    "\n",
    "        # Append the row data to the result_data list\n",
    "        result_data.append([rounded_distance_to_cap] + players_list)\n",
    "    # Create the result DataFrame\n",
    "    column_headings = ['distance_to_cap'] + [f'MD_{md_num}' for md_num in range(1, md + 1)]\n",
    "    cap_matrix = pd.DataFrame(result_data, columns=column_headings)\n",
    "\n",
    "    # Format the player names without square brackets and inverted commas\n",
    "    cap_matrix = cap_matrix.applymap(lambda x: '\\n'.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "    # date_to_gw = fixtures_data[['date_str','gw']].drop_duplicates()\n",
    "    md_map = pd.read_csv('../data/md_map.csv')\n",
    "    headers = list(cap_matrix.columns.values)\n",
    "    sky_gw_header = []\n",
    "    fpl_gw_header = []\n",
    "    for i in headers:\n",
    "        # display(i)\n",
    "        if i.startswith('MD_') == False:\n",
    "            j = 'sky_gw'\n",
    "            k = 'fpl_gw'\n",
    "        else:\n",
    "            matchday = int(i.split('_')[1])\n",
    "            sky_gw = md_map.loc[md_map['matchday']==matchday,'sky_gw'].values[0]\n",
    "            fpl_gw = md_map.loc[md_map['matchday']==matchday,'fpl_gw'].values[0]\n",
    "            j = str(sky_gw)\n",
    "            k = str(fpl_gw)\n",
    "        sky_gw_header.append(j)\n",
    "        fpl_gw_header.append(k)\n",
    "    cap_matrix.columns=[sky_gw_header, fpl_gw_header, headers]\n",
    "\n",
    "    cap_matrix_data = cap_matrix.copy()\n",
    "    \n",
    "    d = dict(selector=\"th\", props=[('text-align', 'center')])\n",
    "    cap_matrix = cap_matrix.style.set_properties(**{'height':'4em', 'width':'4em', 'text-align':'center'})\\\n",
    "        .set_table_styles([d])\n",
    "\n",
    "\n",
    "    def highlight_cols(s, props=''):\n",
    "        return np.where(s!='', props, '')\n",
    "    MDs = [col for col in cap_matrix_data.columns if 'MD_' in col]\n",
    "    # display(cap_matrix_data.columns)\n",
    "    for index, row in cap_matrix_data.iterrows():\n",
    "        rgb_index = index / max_ev_diff\n",
    "        rgb_str = f'rgb({10+15*rgb_index},{10*rgb_index},{40+14*rgb_index})'\n",
    "        cap_matrix = cap_matrix.apply(highlight_cols, props=\"background-color: \"+rgb_str, subset=([index], cap_matrix.columns[1:]))\n",
    "\n",
    "\n",
    "    cap_matrix = cap_matrix.set_properties(**{'color': 'white'},subset=(cap_matrix.columns[1:]))\n",
    "\n",
    "    cap_matrix = cap_matrix.set_table_styles([\n",
    "                        {'selector': 'th.col_heading', 'props': 'text-align: left;'},\n",
    "                        {'selector': 'th.col_heading.level0', 'props': 'font-size: 1em;'},\n",
    "                        {'selector': 'td', 'props': 'text-align: center; font-weight: bold;'},\n",
    "                    ], overwrite=False)\n",
    "\n",
    "    cap_matrix = cap_matrix.format(precision=1)\n",
    "    # Export the resulting table as a CSV file in the data folder\n",
    "    #result_df.to_csv('../data/sky_caps_matrix.csv', index=False)\n",
    "    return cap_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Functions\n",
    "\n",
    "Generate optimal solution for team or analyze multiple simulated runs with noise, based on the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate optimal plan\n",
    "data = {'sky_pos': ['GK', 'DEF', 'MID', 'FOR'],\n",
    "        'squad_min_play': [1, 3, 3, 1],\n",
    "        'squad_max_play': [1, 5 ,5, 3]}\n",
    "type_data = pd.DataFrame(data, index=[1,2,3,4])\n",
    "\n",
    "def solve_sky_mp(initial_squad, input_data, md_map, next_md=1, last_md=10, flatten_mds_after=None,\n",
    "                 ta_tot=50, ta_gw=5, objective='regular', decay_base=0.85, transfer_cost=7.5, \n",
    "                 vicecap_wt = 0.05,\n",
    "                 exclusions=None, keeps=None, ban_teams=None, force_transfer_in=None, force_transfer_out=None, no_transfer_mds=None,\n",
    "                 apply_noise=False, seed_val=None, magnitude=1, show_itb=False, show_non_team_ev=False):\n",
    "    \n",
    "    if decay_base >= 1 or decay_base <=0:\n",
    "        decay_base = 1\n",
    "        objective = 'regular'\n",
    "\n",
    "    def string_day_to_int(input_string):\n",
    "        if str(input_string) == input_string:\n",
    "            if input_string > md_map['unique_dates'].tolist()[-1]:\n",
    "                input_string = md_map.loc[len(md_map)-1, 'matchday']\n",
    "            else:\n",
    "                for i, x in enumerate(md_map['unique_dates'].tolist()):\n",
    "                    if input_string < x:\n",
    "                        input_string = md_map.loc[i, 'matchday'] - 1\n",
    "                        break\n",
    "        if str(input_string) == input_string:\n",
    "            input_string = md_map.loc[len(md_map)-1, 'matchday']\n",
    "        return input_string\n",
    "\n",
    "    last_md = string_day_to_int(last_md)\n",
    "\n",
    "    if flatten_mds_after is not None:\n",
    "        flatten_mds_after = string_day_to_int(flatten_mds_after)\n",
    "        for matchday in range(flatten_mds_after, last_md):\n",
    "            input_data[f'MD_{flatten_mds_after}_Pts'] += input_data[f'MD_{matchday+1}_Pts'] * pow(decay_base, \n",
    "                                                                                                  md_map.loc[md_map['matchday']==matchday, 'sky_gw'].values[0] - md_map.loc[md_map['matchday']==flatten_mds_after, 'sky_gw'].values[0])\n",
    "            input_data = input_data.drop(f'MD_{matchday+1}_Pts', axis=1)\n",
    "        last_md = flatten_mds_after\n",
    "        \n",
    "    horizon = last_md + 1 - next_md\n",
    "    problem_name = f'sky_mp_h{horizon}_d1'\n",
    "    \n",
    "    # Sets\n",
    "    players = input_data.index.tolist()\n",
    "    element_types = type_data.index.tolist()\n",
    "    matchdays = list(range(next_md, next_md+horizon))\n",
    "    cap_mds = [i for i in matchdays if i != flatten_mds_after]\n",
    "    all_md = [next_md-1] + matchdays\n",
    "    \n",
    "    first_gw = int(md_map.loc[md_map['matchday']==next_md, 'sky_gw'].values[0])\n",
    "    last_gw = int(md_map.loc[md_map['matchday']==last_md, 'sky_gw'].values[0])\n",
    "    gameweeks = list(range(first_gw,last_gw+1))\n",
    "    gw_transfer_allowance = {w: 5 for w in gameweeks}\n",
    "    gw_transfer_allowance[first_gw] = min(ta_gw,5)\n",
    "\n",
    "    if apply_noise:\n",
    "        rng = np.random.default_rng(seed = seed_val)\n",
    "        input_data['Total_Pts'] = 0\n",
    "        player_df = pd.read_csv('../data/prior_player_data.csv')\n",
    "        player_df = player_df[['sky_id', 'noise_factor']]\n",
    "        input_data = pd.merge(input_data,player_df,on='sky_id').set_index('sky_id')\n",
    "        for m in matchdays:\n",
    "            # replaced `input_data['noise_factor']` with 1.5 for now\n",
    "            noise = input_data[f'MD_{m}_Pts'] * 0.035 * rng.standard_normal(size = len(input_data)) * magnitude * 1.5 \n",
    "            input_data[f'MD_{m}_Pts'] = input_data[f'MD_{m}_Pts'] + round(noise,2)\n",
    "            input_data['Total_Pts'] += input_data[f'MD_{m}_Pts']\n",
    "\n",
    "    # Model\n",
    "    model = so.Model(name = 'multi_period')\n",
    "\n",
    "    # Variables\n",
    "    squad = model.add_variables(players, all_md, name='squad', vartype=so.binary)\n",
    "    captain = model.add_variables(players, matchdays, name='captain', vartype=so.binary)\n",
    "    vicecap = model.add_variables(players, matchdays, name='vicecap', vartype=so.binary)\n",
    "    transfer_in = model.add_variables(players, matchdays, name='transfer_in', vartype=so.binary)\n",
    "    transfer_out = model.add_variables(players, matchdays, name='transfer_out', vartype=so.binary)\n",
    "    \n",
    "    # Dictionaries\n",
    "    squad_type_count = {(t,d): so.expr_sum(squad[p,d] for p in players if input_data.loc[p, 'sky_pos'] == type_data.loc[t, 'sky_pos']) for t in element_types for d in matchdays}\n",
    "    player_value = (input_data['sky_value']).to_dict()\n",
    "    # bought_amount = {d: so.expr_sum(player_value[p] * transfer_in[p,d] for p in players) for d in matchdays}\n",
    "    # sold_amount = {d: so.expr_sum(player_value[p] * transfer_out[p,d] for p in players) for d in matchdays}\n",
    "    squad_value = {d: so.expr_sum(player_value[p] * squad[p,d] for p in players) for d in matchdays}\n",
    "    points_player_day = {(p,d): input_data.loc[p, f'MD_{d}_Pts'] for p in players for d in matchdays}\n",
    "    squad_count = {d: so.expr_sum(squad[p, d] for p in players) for d in matchdays}\n",
    "    \n",
    "    total_number_of_transfers = so.expr_sum(transfer_out[p,d] for p in players for d in matchdays) \n",
    "\n",
    "    md_number_of_transfers = {d: so.expr_sum(transfer_out[p,d] for p in players) for d in matchdays}        \n",
    "    gw_number_of_transfers = {w: so.expr_sum(md_number_of_transfers[d] for d in matchdays if int(md_map.loc[md_map['matchday']==d, 'sky_gw'].values[0]) == w) for w in gameweeks}\n",
    "    \n",
    "    # Initial Conditions\n",
    "    if initial_squad is not None:\n",
    "        model.add_constraints((squad[p, next_md-1] == 1 for p in initial_squad), name='initial_squad_players')\n",
    "        model.add_constraints((squad[p, next_md-1] == 0 for p in players if p not in initial_squad), name='initial_squad_others')\n",
    "    # Constraints: squad and captaincy\n",
    "    model.add_constraints((squad_count[d] == 11 for d in matchdays), name='squad_count')\n",
    "    model.add_constraints((so.expr_sum(captain[p,d] for p in players) == 1 for d in cap_mds), name='captain_count')\n",
    "    model.add_constraints((captain[p,d] <= squad[p,d] for p in players for d in matchdays), name='captain_squad_rel')\n",
    "    if vicecap_wt > 0 and vicecap_wt < 1:\n",
    "        model.add_constraints((so.expr_sum(vicecap[p,d] for p in players) == 1 for d in cap_mds), name='vicecap_count')\n",
    "        model.add_constraints((vicecap[p,d] <= squad[p,d] for p in players for d in matchdays), name='vicecap_squad_rel')\n",
    "        model.add_constraints((captain[p,d] + vicecap[p,d] <=1 for p in players for d in matchdays), name='cap_vicecap_rel')\n",
    "    else:\n",
    "        model.add_constraints((so.expr_sum(vicecap[p,d] for p in players) == 0 for d in cap_mds), name='no_vicecap')\n",
    "        vicecap_wt = 0\n",
    "    if flatten_mds_after is not None:\n",
    "        model.add_constraints((captain[p,flatten_mds_after] + vicecap[p,flatten_mds_after] == 0 for p in players), name='no_cap_flattened_md')\n",
    "    # Constraints: formation and budget\n",
    "    model.add_constraints((squad_type_count[t,d] == [type_data.loc[t, 'squad_min_play'], type_data.loc[t, 'squad_max_play']] for t in element_types for d in matchdays), name='valid_formation_1')\n",
    "    model.add_constraints((squad_type_count[2,d]-squad_type_count[4,d] <= 3.5 for d in matchdays), name='valid_formation_2')\n",
    "    model.add_constraints((squad_value[d] <= 100 for d in matchdays), name='squad_budget')\n",
    "    # Constraints: transfers\n",
    "    model.add_constraints((squad[p,d] == squad[p,d-1] + transfer_in[p,d] - transfer_out[p,d] for p in players for d in matchdays), name='squad_transfer_rel')\n",
    "    model.add_constraint(total_number_of_transfers <= min(ta_tot,50), name = 'transfer_allowance')\n",
    "    model.add_constraints((gw_number_of_transfers[w] <= gw_transfer_allowance[w] for w in gameweeks), name = 'gw_transfer_allowance')\n",
    "    if no_transfer_mds is not None:\n",
    "        model.add_constraints((md_number_of_transfers[m] == 0 for m in no_transfer_mds), name='no_transfer_matchdays')\n",
    "    # Constraints: specified players\n",
    "    # Ban teams\n",
    "    if ban_teams is not None:\n",
    "        if exclusions is None:\n",
    "            exclusions = []\n",
    "        for index, row in input_data.iterrows():\n",
    "            if row['short_team'] in ban_teams:\n",
    "                exclusions += [index]\n",
    "    # Force Exclude\n",
    "    if exclusions is not None:\n",
    "        model.add_constraints((squad[e, d] == 0 for e in exclusions for d in matchdays), name = 'force_exclude_players')\n",
    "    # Force Keep\n",
    "    if keeps is not None:\n",
    "        model.add_constraints((squad[e, d] == 1 for e in keeps for d in matchdays), name = 'force_keep_players')\n",
    "    # Force transfer in\n",
    "    if force_transfer_in is not None:\n",
    "        fti_any = []\n",
    "        fti_spec = []\n",
    "        for constraint_dict in force_transfer_in:\n",
    "            if \"md\" not in constraint_dict:\n",
    "                fti_any.append(constraint_dict)\n",
    "            else:\n",
    "                fti_spec.append(constraint_dict)\n",
    "        if len(fti_any) > 0.5:\n",
    "            # suppress singular constraint warning message \n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\") \n",
    "                model.add_constraints((so.expr_sum(transfer_in[fti_any[e][\"sky_id\"], d] for e in list(range(len(fti_any))) for d in matchdays) >= 1), name='force_transfer_in_any')\n",
    "        if len(fti_spec) > 0.5:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                model.add_constraints((transfer_in[fti_spec[e][\"sky_id\"], fti_spec[e][\"md\"]] == 1 for e in list(range(len(fti_spec)))), name = 'force_transfer_in_specified')\n",
    "                model.add_constraints((transfer_out[fti_spec[e][\"sky_id\"], fti_spec[e][\"md\"]] == 0 for e in list(range(len(fti_spec)))), name = 'force_transfer_in_specified_lock')\n",
    "    # Force transfer out\n",
    "    if force_transfer_out is not None:\n",
    "        fto_any = []\n",
    "        fto_spec = []\n",
    "        for constraint_dict in force_transfer_out:\n",
    "            if \"md\" not in constraint_dict:\n",
    "                fto_any.append(constraint_dict)\n",
    "            else:\n",
    "                fto_spec.append(constraint_dict)\n",
    "        if len(fto_any) > 0.5:\n",
    "            # suppress singular constraint warning message \n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\") \n",
    "                model.add_constraints((so.expr_sum(transfer_out[fto_any[e][\"sky_id\"], d] for e in list(range(len(fto_any))) for d in matchdays) >= 1), name='force_transfer_out_any')\n",
    "        if len(fto_spec) > 0.5:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                model.add_constraints((transfer_out[fto_spec[e][\"sky_id\"], fto_spec[e][\"md\"]] == 1 for e in list(range(len(fto_spec)))), name = 'force_transfer_out_specified')\n",
    "                model.add_constraints((transfer_in[fto_spec[e][\"sky_id\"], fto_spec[e][\"md\"]] == 0 for e in list(range(len(fto_spec)))), name = 'force_transfer_out_specified_lock')\n",
    "\n",
    "    # Objective\n",
    "    md_xp = {d: so.expr_sum(points_player_day[p,d] * (squad[p,d] + captain[p,d] + vicecap_wt*vicecap[p,d]) for p in players) for d in matchdays}\n",
    "    if objective == 'regular':\n",
    "        # Note `- 0.0001*md_number_of_transfers[d]*d` gives a negligible incentive to make a transfer as late as possible\n",
    "        eval_score = so.expr_sum(md_xp[d] + 0.0001*md_number_of_transfers[d]*d for d in matchdays) - total_number_of_transfers*transfer_cost\n",
    "        model.set_objective(-eval_score, sense='N', name='total_regular_xp') \n",
    "    else:\n",
    "        # eval_score = so.expr_sum(md_xp[d] * pow(decay_base, d-next_md) for d in matchdays) - total_number_of_transfers*transfer_cost\n",
    "        days_elapsed0 = md_map.loc[md_map['matchday']==next_md,'days_elapsed'].values[0]\n",
    "        # Convert weekly decay to daily\n",
    "        decay_base = decay_base ** (1/7)\n",
    "        eval_score = so.expr_sum(md_xp[d] * pow(decay_base, md_map.loc[md_map['matchday']==d,'days_elapsed'].values[0]-days_elapsed0) + 0.0001*md_number_of_transfers[d]*d for d in matchdays) - total_number_of_transfers*transfer_cost\n",
    "        model.set_objective(-eval_score, sense='N', name='total_decay_xp')\n",
    "    \n",
    "    # Solve Step\n",
    "    model.export_mps(filename='skyoutput.mps')\n",
    "    command = f'cbc skyoutput.mps solve solu {problem_name}_sol.txt'\n",
    "    # !{command}\n",
    "    os.system(command)\n",
    "    # Read the solution back to the file\n",
    "    with open(f'{problem_name}_sol.txt', 'r') as f:\n",
    "        for v in model.get_variables():\n",
    "            v.set_value(0)\n",
    "        for line in f:\n",
    "            if 'objective value' in line:\n",
    "                continue\n",
    "            words = line.split()\n",
    "            var = model.get_variable(words[1])\n",
    "            var.set_value(float(words[2]))\n",
    "            \n",
    "    # (OLD) Generate a dataframe to display the solution \n",
    "    picks = []\n",
    "    for d in matchdays:\n",
    "        for p in players:\n",
    "            if squad[p,d].get_value() + transfer_out[p,d].get_value() > 0.5:\n",
    "                lp = input_data.loc[p]\n",
    "                is_captain = 1 if captain[p,d].get_value() > 0.5 else 0\n",
    "                is_transfer_in = 1 if transfer_in[p,d].get_value() > 0.5 else 0\n",
    "                is_transfer_out = 1 if transfer_out[p,d].get_value() > 0.5 else 0\n",
    "                picks.append([\n",
    "                    int(md_map.loc[md_map['matchday']==d, 'sky_gw'].values[0]), d, lp['fbref_player'], lp['sky_pos'], lp['short_team'], lp['sky_value'], round(points_player_day[p,d], 2), is_captain, is_transfer_in, is_transfer_out\n",
    "                ])\n",
    "    picks_df = pd.DataFrame(picks, columns=['sky_gw','matchday','name', 'pos', 'team', 'value', 'xP', 'captain', 'transfer_in', 'transfer_out'])#.sort_values(by=['matchday'])\n",
    "    picks_df.loc[picks_df['matchday'] == next_md, 'transfer_in'] = 0\n",
    "    \n",
    "    eval_score = round(eval_score.get_value(),2)\n",
    "    total_xp = round(so.expr_sum(points_player_day[p,d] * (squad[p,d] + captain[p,d]) for p in players for d in matchdays).get_value(), 2)\n",
    "    \n",
    "    # Generate a better dataframe to display the solution\n",
    "    plan = []\n",
    "    for t in element_types:\n",
    "        for p in players:\n",
    "            if so.expr_sum(squad[p,d] + transfer_out[p,d] for d in matchdays).get_value() >= 0.5 and input_data.loc[p, 'sky_pos'] == type_data.loc[t, 'sky_pos']:\n",
    "                lp = input_data.loc[p]\n",
    "                player_info = [p, lp['short_team'], lp['sky_pos'][0], lp['sky_value'], lp['fbref_player']]\n",
    "                for d in matchdays:\n",
    "                    current_points = points_player_day[p,d]\n",
    "                    if squad[p,d].get_value() > 0.5:\n",
    "                        score = f'{round(current_points, 2)}'\n",
    "                        if captain[p,d].get_value() > 0.5:\n",
    "                            score += 'c'\n",
    "                        if vicecap[p,d].get_value() > 0.5:\n",
    "                            score += 'v'\n",
    "                    elif show_non_team_ev and current_points > 0.2:\n",
    "                        score = f'({round(current_points, 2)})'\n",
    "                    else:\n",
    "                        score = ''\n",
    "                    player_info.append(score)\n",
    "                plan.append(player_info)\n",
    "    columns = ['ID','Team', 'Pos','Value','Name']\n",
    "    for d in matchdays:\n",
    "        # w = int(md_map.loc[md_map['matchday']==d, 'sky_gw'].values[0])\n",
    "        columns.append(f\"{d}\")\n",
    "    plan_df = pd.DataFrame(plan, columns=columns)\n",
    "    plan_df = plan_df.replace(['0.0'],'-')\n",
    "    plan_df = plan_df.replace(['0.0c'],'-')\n",
    "    plan_df = plan_df.replace(['0.0v'],'-')\n",
    "\n",
    "    if show_itb:\n",
    "        itb_row = ['','','','','ITBm']\n",
    "        for d in matchdays:\n",
    "            itb = abs(100 - squad_value[d].get_value())\n",
    "            itb_row.append(itb)\n",
    "        plan_df.loc[len(plan_df)] = itb_row\n",
    "\n",
    "    # make dataframe to record the players in a simulation\n",
    "    plan = []\n",
    "    if apply_noise:\n",
    "        for t in element_types:\n",
    "            for p in players:\n",
    "                if so.expr_sum(squad[p,d] + transfer_out[p,d] for d in matchdays).get_value() >= 0.5 and input_data.loc[p, 'sky_pos'] == type_data.loc[t, 'sky_pos']:\n",
    "                    lp = input_data.loc[p]\n",
    "                    player_info = [p, lp['short_team'], lp['sky_pos'][0], lp['sky_value'], lp['fbref_player']]\n",
    "                    for d in matchdays:\n",
    "                        if squad[p,d].get_value() > 0.5:\n",
    "                            score = 1\n",
    "                        else:\n",
    "                            score = 0\n",
    "                        player_info.append(score)\n",
    "                    plan.append(player_info)\n",
    "        columns = ['ID','Team', 'Pos','Value','Name']\n",
    "        for d in matchdays:\n",
    "            # w = int(md_map.loc[md_map['matchday']==d, 'sky_gw'].values[0])\n",
    "            columns.append(f\"{d}\")\n",
    "        players_in_sim = pd.DataFrame(plan, columns=columns)\n",
    "    else:\n",
    "        players_in_sim = None\n",
    "    \n",
    "    sky_gw_header = []\n",
    "    fpl_gw_header = []\n",
    "    for i in columns:\n",
    "        if i == 'Name':\n",
    "            j = 'sky_gw'\n",
    "            k = 'fpl_gw'\n",
    "        elif not str(i)[0].isdigit():\n",
    "            j = ''\n",
    "            k = ''\n",
    "        else:\n",
    "            sky_gw = md_map.loc[md_map['matchday']==int(i),'sky_gw'].values[0]\n",
    "            fpl_gw = md_map.loc[md_map['matchday']==int(i),'fpl_gw'].values[0]\n",
    "            j = str(sky_gw)\n",
    "            k = str(fpl_gw)\n",
    "        sky_gw_header.append(j)\n",
    "        fpl_gw_header.append(k)\n",
    "    plan_df.columns=[sky_gw_header, fpl_gw_header, columns]\n",
    "\n",
    "    transfers_made = int(total_number_of_transfers.get_value())\n",
    "    \n",
    "    return{'model': model, 'picks': picks_df, 'total_xp': total_xp, 'eval_score': eval_score, 'plan': plan_df, 'transfers_made': transfers_made, 'players_in_sim': players_in_sim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce sensitivity analysis with noise\n",
    "def solve_sky_mp_noise(initial_squad, input_data, md_map, next_md=1, last_md=10, flatten_mds_after=None,\n",
    "                       ta_tot=50, ta_gw=5, objective='regular', decay_base=0.85, transfer_cost=7.5, \n",
    "                       vicecap_wt = 0.05,\n",
    "                       exclusions=None, keeps=None, ban_teams=None, force_transfer_in=None, force_transfer_out=None, no_transfer_mds=None,\n",
    "                       show_itb=False, show_non_team_ev=False,\n",
    "                       seed_val=None, nsims=5, magnitude=1):\n",
    "    transfer_sum = 0\n",
    "    xp_sum = 0\n",
    "    eval_sum = 0\n",
    "\n",
    "    baseline_projection_df = input_data\n",
    "\n",
    "    results_dict = {}\n",
    "\n",
    "    for i in range(nsims):\n",
    "        print(f\"Running sim {i+1} of {nsims}...\")\n",
    "        input_data = baseline_projection_df.copy()\n",
    "        results = solve_sky_mp(initial_squad=initial_squad, input_data=input_data, md_map=md_map, next_md=next_md, last_md=last_md, flatten_mds_after=flatten_mds_after,\n",
    "                    ta_tot=ta_tot, ta_gw=ta_gw, objective=objective, decay_base=decay_base, transfer_cost=transfer_cost,\n",
    "                    exclusions=exclusions, keeps=keeps, ban_teams=ban_teams, force_transfer_in=force_transfer_in, force_transfer_out=force_transfer_out, no_transfer_mds=no_transfer_mds,\n",
    "                    show_itb=show_itb, show_non_team_ev=show_non_team_ev,\n",
    "                    apply_noise=True, seed_val=seed_val, magnitude=magnitude)\n",
    "        results_dict[i] = results['plan']\n",
    "        players_in_sim = results['players_in_sim']\n",
    "        if i == 0:\n",
    "            sensitivity_df = players_in_sim\n",
    "        else:\n",
    "            for index, row in results['players_in_sim'].iterrows():\n",
    "                if row['ID'] in sensitivity_df['ID'].tolist():\n",
    "                    sensitivity_df.loc[sensitivity_df['ID']==row['ID'], '1':] = sensitivity_df.loc[sensitivity_df['ID']==row['ID'], '1':] + row['1':]\n",
    "                    continue\n",
    "                else:\n",
    "                    row_to_append = row.tolist()\n",
    "                    sensitivity_df.loc[len(sensitivity_df)] = row_to_append\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        transfer_sum += results['transfers_made']\n",
    "        xp_sum += results['total_xp']\n",
    "        eval_sum += results['eval_score']\n",
    "    avg_trf = round(transfer_sum/nsims,2)\n",
    "    avg_xp = round(xp_sum/nsims,2)\n",
    "    avg_eval = round(eval_sum/nsims,2)\n",
    "    # display(sensitivity_df)\n",
    "    # sensitivity_df.loc[:,'1':] = sensitivity_df.loc[:,'1':].astype(int)\n",
    "    sensitivity_df.loc[:,'1':] = sensitivity_df.loc[:,'1':] * 100 / nsims\n",
    "    # sensitivity_df.loc[:,'1':] = round(sensitivity_df.loc[:,'1':],0)\n",
    "    sensitivity_df.loc[:,'1':] = sensitivity_df.loc[:,'1':].astype(int)\n",
    "\n",
    "    # Sort the dataframe by initial team and position\n",
    "    sensitivity_df['max_ocuurences'] = 0\n",
    "    sensitivity_df['init_team'] = 0\n",
    "    sensitivity_df['pos_code'] = 0\n",
    "    for index, row in sensitivity_df.iterrows():\n",
    "        if row['Pos'] == 'G':\n",
    "            sensitivity_df.loc[index,'pos_code'] = 1\n",
    "        elif row['Pos'] == 'D':\n",
    "            sensitivity_df.loc[index,'pos_code'] = 2\n",
    "        elif row['Pos'] == 'M':\n",
    "            sensitivity_df.loc[index,'pos_code'] = 3\n",
    "        else:\n",
    "            sensitivity_df.loc[index,'pos_code'] = 4\n",
    "        if row['ID'] in initial_squad:\n",
    "            sensitivity_df.loc[index,'init_team'] = 1\n",
    "    sensitivity_df = sensitivity_df.sort_values(by=['pos_code', 'init_team'], ascending=[True, False])\n",
    "    sensitivity_df.drop(['max_ocuurences', 'init_team', 'pos_code'], axis=1, inplace=True)\n",
    "    \n",
    "    columns = sensitivity_df.columns.values.tolist()\n",
    "\n",
    "    sky_gw_header = []\n",
    "    fpl_gw_header = []\n",
    "    for i in columns:\n",
    "        if i == 'Name':\n",
    "            j = 'sky_gw'\n",
    "            k = 'fpl_gw'\n",
    "        elif not str(i)[0].isdigit():\n",
    "            j = ''\n",
    "            k = ''\n",
    "        else:\n",
    "            sky_gw = md_map.loc[md_map['matchday']==int(i),'sky_gw'].values[0]\n",
    "            fpl_gw = md_map.loc[md_map['matchday']==int(i),'fpl_gw'].values[0]\n",
    "            j = str(sky_gw)\n",
    "            k = str(fpl_gw)\n",
    "        sky_gw_header.append(j)\n",
    "        fpl_gw_header.append(k)\n",
    "    sensitivity_df.columns=[sky_gw_header, fpl_gw_header, columns]\n",
    "\n",
    "    sens = sensitivity_df.copy()\n",
    "    sens = sens.style.background_gradient(cmap=\"RdPu\", subset=sensitivity_df.columns[5:]).format(precision=1)\n",
    "    # sens.set_properties(**{'text-align': 'left'})\n",
    "    sens = sens.set_table_styles([\n",
    "                        {'selector': 'th.col_heading', 'props': 'text-align: left;'},\n",
    "                        {'selector': 'th.col_heading.level0', 'props': 'font-size: 1em;'},\n",
    "                        {'selector': 'td', 'props': 'text-align: center; font-weight: bold;'},\n",
    "                    ], overwrite=False)\n",
    "                \n",
    "    return {'sensitivity_df': sens, 'avg_trf': avg_trf, 'avg_xp': avg_xp, 'avg_eval': avg_eval, 'sensitivity_df_unformatted': sensitivity_df, 'results_dict': results_dict}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver Commands\n",
    "Commands to generate EV and optimal plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate player EV from the fixtures:\n",
    "# Change player or team underlyings as you see fit in prior_player_data.csv and team_priors.csv\n",
    "# Penalty takers can be overridden in pen_taker_override.csv\n",
    "# Adding an fplreview.csv to the data folder will let the model use its xMins. Alternatively, edit bl_xmins in prior_player_data.csv to manually override them \n",
    "\n",
    "# Example custom fixtures dataframe to add, move, or remove fixtures and assign probabilities of occuring\n",
    "# Leave 'custom_fixtures=None' to keep the fixtures as they are on the PL site\n",
    "df = pd.DataFrame(columns=('home_team', 'away_team', 'dates', 'probabilities'))\n",
    "\n",
    "# Many possibilities for rescheduling BOULUT: GWs 27, 28, 32, 33, 34, 35, 36, 37 all work\n",
    "df.loc[len(df)] = ['BOU', 'LUT', ['2024-03-05', '2024-03-12', '2024-04-09', '2024-04-23', '2024-05-14'], [0.1, 0.6, 0.1, 0.1, 0.1]]\n",
    "df.loc[len(df)] = ['CHE', 'TOT', ['2024-02-23', '2024-04-23', '2024-05-14'], [0.05, 0.48, 0.27]]\n",
    "\n",
    "# BGW29\n",
    "df.loc[len(df)] = ['BHA', 'MCI', ['2024-03-17', '2024-04-23', '2024-05-14'], [0.06, 0.77, 0.19]]\n",
    "df.loc[len(df)] = ['EVE', 'LIV', ['2024-03-17', '2024-04-23', '2024-05-14'], [0.14, 0.77, 0.09]]\n",
    "df.loc[len(df)] = ['MUN', 'SHU', ['2024-03-16', '2024-04-23', '2024-05-14'], [0.38, 0.50, 0.12]]\n",
    "df.loc[len(df)] = ['CRY', 'NEW', ['2024-03-16', '2024-04-23', '2024-05-14'], [0.23, 0.62, 0.15]]\n",
    "df.loc[len(df)] = ['WOL', 'BOU', ['2024-03-16', '2024-04-23', '2024-05-14'], [0.20, 0.64, 0.16]]\n",
    "df.loc[len(df)] = ['ARS', 'CHE', ['2024-03-16', '2024-04-23', '2024-05-14'], [0.67, 0.26, 0.07]]\n",
    "df.loc[len(df)] = ['WHU', 'AVL', ['2024-03-17', '2024-04-23', '2024-05-14'], [0.54, 0.37, 0.09]]\n",
    "df.loc[len(df)] = ['LUT', 'FOR', ['2024-03-16', '2024-04-23', '2024-05-14'], [0.64, 0.29, 0.07]]\n",
    "\n",
    "# Shuffling in GW34\n",
    "df.loc[len(df)] = ['FUL', 'LIV', ['2024-04-20', '2024-04-23', '2024-05-14'], [0.40, 0.09, 0.51]]\n",
    "df.loc[len(df)] = ['LUT', 'BRE', ['2024-04-20', '2024-04-23', '2024-05-14'], [0.95, 0.02, 0.03]]\n",
    "df.loc[len(df)] = ['AVL', 'BOU', ['2024-04-20', '2024-04-23', '2024-05-14'], [0.53, 0.11, 0.36]]\n",
    "df.loc[len(df)] = ['BHA', 'CHE', ['2024-04-20', '2024-04-23', '2024-05-14'], [0.58, 0.07, 0.35]]\n",
    "df.loc[len(df)] = ['EVE', 'FOR', ['2024-04-20', '2024-04-23', '2024-05-14'], [0.89, 0.02, 0.09]]\n",
    "df.loc[len(df)] = ['MUN', 'NEW', ['2024-04-20', '2024-04-23', '2024-05-14'], [0.37, 0.16, 0.47]]\n",
    "df.loc[len(df)] = ['TOT', 'MCI', ['2024-04-20', '2024-04-23', '2024-05-14'], [0.32, 0.11, 0.56]]\n",
    "df.loc[len(df)] = ['WOL', 'ARS', ['2024-04-20', '2024-04-23', '2024-05-14'], [0.80, 0.05, 0.15]]\n",
    "\n",
    "# Generate fixture ticker and player EV\n",
    "# Setting \"teamsheet_boost\" to a positive decimal (e.g. 0.05) will boost the EV of players for whom the teamsheet will be released before the deadline\n",
    "# Set the last matchday, last_md, as an integer, or a date as a string in the format 'YYYY-mm-dd'\n",
    "r2 = generate_model_output(first_md=1, last_md='2024-05-19', filename_suffix=None, custom_fixtures=df, teamsheet_boost=0.05, dynamic_pens=True)\n",
    "display(r2['formatted_fixtures'])\n",
    "# display(r2['unformatted_fixtures'])\n",
    "display(r2['skymodel_output'].sort_values(by=['Total_Pts'], ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate optimal team and plan:\n",
    "# List all the sky IDs of all players to include in the initial squad (or leave empty), see prior_player_data.csv for ID reference\n",
    "team = []\n",
    "exclusions = None\n",
    "\n",
    "# Change how much you penalize the solver for making a transfer, alternatively set a hard limit by changing the total transfer allowance: ta_tot\n",
    "transfer_cost = 9\n",
    "\n",
    "# Example force transfer in constraints, either let the model decide when or specify a matchday\n",
    "# fti = [{\"sky_id\": 610}, {\"sky_id\": 1072, \"md\": 3}, {\"sky_id\": 398, \"md\": 6}]\n",
    "fti = None\n",
    "fto = None\n",
    "\n",
    "# To use FPL Kid data, download the 'SKY Fantasy EV - CSV' google sheet as fplkid.csv, add to data folder, and uncomment the following line. https://ko-fi.com/fplkid\n",
    "# skymodel_output, md_map = read_fpl_kid_model(filepath='../data/fplkid.csv')\n",
    "# Can cut off players with low EV to save solve time\n",
    "skymodel_output, md_map = read_skymodel_output(max_ev_cutoff=0.3, max_ev_per_price_cutoff=0.3, initial_squad=team)\n",
    "# Generate optimal plan\n",
    "r3 = solve_sky_mp(initial_squad=team, input_data=skymodel_output, md_map=md_map, next_md=1, last_md='2024-05-19', flatten_mds_after='2024-04-06',\n",
    "                  ta_tot=25, ta_gw=5, objective='decay', decay_base=0.97, transfer_cost=transfer_cost, vicecap_wt = 0.05,\n",
    "                  exclusions=exclusions, keeps=None, ban_teams=None, force_transfer_in=fti, force_transfer_out=fto, no_transfer_mds=None,\n",
    "                  apply_noise=False, show_itb=True, show_non_team_ev=False)\n",
    "display(r3['plan'])\n",
    "print(f\"Total xP: {r3['total_xp']}\\t Eval: {r3['eval_score']}\")\n",
    "print(f\"Total transfers made: {r3['transfers_made']}\\t Transfer cost: {transfer_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run multiple solves with noise:\n",
    "team = []\n",
    "\n",
    "transfer_cost = 9\n",
    "# Choose a number of simulations to run (20 recommended at the minimum for more reliable results)\n",
    "nsims = 50\n",
    "# Choose the relative magnitude of applied noise, the higher the number the more diverse the generated plans will be (1 to 3 is common)\n",
    "magnitude = 3\n",
    "\n",
    "skymodel_output, md_map = read_skymodel_output(max_ev_cutoff=0.3, max_ev_per_price_cutoff=0.3, initial_squad=team)\n",
    "# Generate sensitivity analysis\n",
    "r4 = solve_sky_mp_noise(initial_squad=team, input_data=skymodel_output, md_map=md_map, next_md=1, last_md='2024-05-19', flatten_mds_after='2024-04-06',\n",
    "                        ta_tot=25, ta_gw=5, objective='decay', decay_base=0.97, transfer_cost=transfer_cost, vicecap_wt = 0.05,\n",
    "                        exclusions=None, keeps=None, ban_teams=None, force_transfer_in=None, force_transfer_out=None, no_transfer_mds=None,\n",
    "                        show_itb=True, show_non_team_ev=False,\n",
    "                        seed_val=None, nsims=nsims, magnitude=magnitude)\n",
    "results_dict = r4['results_dict']\n",
    "display(r4['sensitivity_df'])\n",
    "# display(r4['sensitivity_df_unformatted'])\n",
    "print(f\"Number of sims: {nsims}\\t\\tTransfer cost: {transfer_cost}\\tNoise magnitude: {magnitude}\\nAvg transfers made: {r4['avg_trf']}\\t  xPts: {r4['avg_xp']}\\t\\tEval: {r4['avg_eval']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To just see the upcoming fixtures:\n",
    "r0 = generate_ticker()\n",
    "r0['formatted_fixtures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see a breakdown of EV for a given player and fixture:\n",
    "prior_player_data = pd.read_csv('../data/prior_player_data.csv')\n",
    "team_data = pd.read_csv('../data/team_priors.csv')\n",
    "# Find a players sky_id in prior_player_data.csv\n",
    "# opp_team is case sensitive, uppercase and lowercase implying home and away respectively\n",
    "# r1 = sky_xP_calc(sky_id=377, opp_team='BHA', prior_player_data=prior_player_data, team_data=team_data, xMins=85, xP_breakdown=True)\n",
    "r1 = sky_xP_calc(sky_id=72, opp_team='WOL', prior_player_data=prior_player_data, team_data=team_data, xMins=90, xP_breakdown=True)\n",
    "\n",
    "r1['xP_breakdown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view the upcoming captaincy matrix first generate player EV then:\n",
    "generate_cap_matrix(last_md=19, max_ev_diff=1.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92da1a170ecb0018a71137dc8b8687270834efb85fe22800f1b77b06a6422852"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
